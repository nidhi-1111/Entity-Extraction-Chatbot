{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "(1) This script implments a BERT model chatbot:\n",
        "\n",
        "1. Loads a pre-trained BERT tokenizer and model.\n",
        "2. Preprocesses user input and FAQ questions.\n",
        "3. Computes embeddings for FAQ questions and stores them.\n",
        "4. Matches user queries to the most similar FAQ answer using cosine similarity.\n",
        "5. Provides a command-line interface for interactive querying.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4lcnVOCXZpV"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import json\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import BertTokenizer, BertModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load pre-trained BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Preprocess text (simple tokenization and lowercasing)\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'\\W+', ' ', text)  # Remove non-alphanumeric characters\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    return text\n",
        "\n",
        "# Generate BERT embeddings\n",
        "def get_bert_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
        "    outputs = model(**inputs)\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
        "    return embeddings.detach().numpy()\n",
        "\n",
        "# Find the best matching answer\n",
        "def get_best_answer(user_query, faqs, faq_embeddings):\n",
        "    preprocessed_query = preprocess_text(user_query)\n",
        "    query_embedding = get_bert_embedding(preprocessed_query).reshape(1, -1)\n",
        "    \n",
        "    similarities = cosine_similarity(query_embedding, faq_embeddings)\n",
        "    best_match_index = similarities.argmax()\n",
        "    return faqs[best_match_index]['answer']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkQ-J8NoXrE-"
      },
      "outputs": [],
      "source": [
        "# Load the FAQs from the JSON file\n",
        "with open('data/keelworks_info.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "faqs = data['questions_and_answers']\n",
        "\n",
        "# Precompute embeddings for FAQ questions\n",
        "faq_embeddings = [get_bert_embedding(preprocess_text(faq['question'])) for faq in faqs]\n",
        "faq_embeddings = np.vstack(faq_embeddings)  # Ensure embeddings are in a 2D array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3U6vOQcqYtQo",
        "outputId": "44bb5d45-3c8e-43a9-ba2a-9f0435886f98"
      },
      "outputs": [],
      "source": [
        "# Command-Line Interface\n",
        "def chatbot():\n",
        "    print(\"Welcome to the KeelWorks Chatbot! Ask me anything about KeelWorks.\")\n",
        "    while True:\n",
        "        user_query = input(\"\\nYou: \")\n",
        "        if user_query.lower() in ['exit', 'quit', 'bye']:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "        answer = get_best_answer(user_query, faqs, faq_embeddings)\n",
        "        print(f\"Bot: {answer}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    chatbot()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
